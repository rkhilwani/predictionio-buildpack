#!/bin/bash

# Fail immediately on non-zero exit code.
set -e
# Fail immediately on non-zero exit code within a pipeline.
set -o pipefail
# Fail on undeclared variables.
set -u
# Debug, echo every command
#set -x

function error() {
  echo " !     $*" >&2
  exit 1
}

function topic() {
  echo "-----> $*"
}

function indent() {
  c='s/^/       /'
  case $(uname) in
    Darwin) sed -l "$c";;
    *)      sed -u "$c";;
  esac
}

# Simply returns the version string
get_predictionio_version() {
  local template_json=$1
  if [ -e $template_json ]
  then
    cat $template_json | ruby \
      -E utf-8:utf-8 \
      -r json \
      -e "STDOUT << JSON.parse(STDIN.read)['pio']['version']['min']"
  else
    # without a template file, assume we're build the eventserver on the newest version
    echo '0.12.0-incubating'
  fi
}

# The build dir is the first arg or calling script current dir.
BUILD_DIR="${1:-$(pwd)}"
echo "---------> BUILD_DIR $BUILD_DIR"
# The buildpack dir is the first are, or two directories up from this script.
BP_DIR="${2:-$(cd $(dirname ${0:-}); cd ../..; pwd)}"
echo "-----------> BP_DIR $BP_DIR"

POSTGRESQL_DRIVER=https://marsikai.s3.amazonaws.com/postgresql-9.4.1209.jar
HADOOP_AWS_SUPPORT=https://marsikai.s3.amazonaws.com/hadoop-aws-2.7.3.jar
AWS_SDK=https://marsikai.s3.amazonaws.com/aws-java-sdk-1.7.4.jar
ELASTICSEARCH_DIST_URL=https://marsikai.s3.amazonaws.com/elasticsearch-5.5.2.tar.gz

requires_pio_version=$(get_predictionio_version "$BUILD_DIR/template.json")
echo 'version '
echo
if [[ $requires_pio_version =~ ^0\.10 ]]
  then
  echo "PredictionIO 0.10.0-incubating is no longer supported by this buildpack." | indent
  echo "  More info: https://github.com/heroku/predictionio-buildpack/pull/44" | indent
  exit 1
elif [[ $requires_pio_version =~ ^0\.11\.0-SNAPSHOT ]]
  then
  PIO_VERSION=0.11.0-SNAPSHOT-esclient-auth-with-batch-predict-v12
  PIO_BUILD_SPARK_VERSION=2.1.0
elif [[ $requires_pio_version =~ ^0\.11 ]]
  then
  PIO_VERSION=0.11.0-incubating
  PIO_BUILD_SPARK_VERSION=2.1.0
elif [[ $requires_pio_version =~ ^0\.12 ]]
  then
  PIO_VERSION=0.12.0-incubating
  PREDICTIONIO_DIST_URL="${PREDICTIONIO_DIST_URL:-https://dist.apache.org/repos/dist/release/incubator/predictionio/0.12.0-incubating/apache-predictionio-0.12.0-incubating-bin.tar.gz}"
elif [[ $requires_pio_version =~ ^0\.14 ]]
  then
  PIO_VERSION=0.14.0
  PIO_BUILD_SPARK_VERSION=2.1.3
  PREDICTIONIO_DIST_URL="${PREDICTIONIO_DIST_URL:-https://dist.apache.org/repos/dist/release/predictionio/0.14.0/apache-predictionio-0.14.0-bin.tar.gz}"
else
  echo "The PredictionIO version specified in template.json ($requires_pio_version) is not compatible." | indent
  exit 1
fi

PIO_BUILD=PredictionIO-${PIO_VERSION}
SPARK_VERSION="spark-${PIO_BUILD_SPARK_VERSION:-2.1.3}-bin-hadoop${PIO_BUILD_HADOOP_VERSION:-2.7}"

# PredictionIO dist tarball URL, expects `.tar.gz` 
# default_url="https://marsikai.s3.amazonaws.com/${PIO_BUILD}.tar.gz"
url="${PREDICTIONIO_DIST_URL-$default_url}"
echo "-------> url $url"

# The PATH set in .profile.d/pio-env.sh must match.
export PIO_DIST_NAME="PredictionIO-dist"
export PIO_DIST_DIR="$BUILD_DIR/$PIO_DIST_NAME"

topic 'Install core components'

echo "+ PredictionIO (${PIO_VERSION})" | indent
curl -s -L "$url" > "${PIO_DIST_NAME}.tar.gz"
mkdir -p "$PIO_DIST_DIR"
tar -xz -f "${PIO_DIST_NAME}.tar.gz" -C "$PIO_DIST_DIR" --strip-components=1 | indent
rm "${PIO_DIST_NAME}.tar.gz"

echo "+ Spark (${SPARK_VERSION})" | indent
SPARK_HOME_DIR="$PIO_DIST_DIR/vendors/spark-hadoop"
curl -s -L "https://archive.apache.org/dist/spark/spark-2.1.3/spark-2.1.3-bin-hadoop2.7.tgz" > "spark-hadoop.tar.gz"
mkdir -p "$SPARK_HOME_DIR"
tar -xz -f "spark-hadoop.tar.gz" -C "$SPARK_HOME_DIR" --strip-components=1  | indent
rm "spark-hadoop.tar.gz"

topic 'Install supplemental components'

echo "+ PostgreSQL (JDBC)" | indent
pio_lib_dir=$PIO_DIST_DIR/lib
mkdir -p $pio_lib_dir
curl -s -L "$POSTGRESQL_DRIVER" > "$pio_lib_dir/postgresql_jdbc.jar"

if [ "${PIO_S3_BUCKET_NAME:-}" ]
  then
  spark_lib_dir=$PIO_DIST_DIR/lib/spark
  mkdir -p $spark_lib_dir
  echo "+ S3 HDFS (AWS SDK)" | indent
  curl -s -L "$AWS_SDK" > "$spark_lib_dir/aws-java-sdk.jar"
  echo "+ S3 HDFS (Hadoop-AWS)" | indent
  curl -s -L "$HADOOP_AWS_SUPPORT" > "$spark_lib_dir/hadoop-aws.jar"
  # Overrideable config file
  default_hadoop="$BP_DIR/config/core-site.xml.erb"
  custom_hadoop="$BUILD_DIR/config/core-site.xml.erb"
  target_hadoop="${PIO_DIST_DIR}/conf/core-site.xml.erb"
  if [ -f "${custom_hadoop}" ]
    then
    echo "  Using custom 'config/core-site.xml.erb'" | indent
    cp "${custom_hadoop}" "${target_hadoop}" | indent
  else
    echo "  Writing default 'core-site.xml.erb'" | indent
    cp "${default_hadoop}" "${target_hadoop}" | indent
  fi
fi

if [ "${PIO_ELASTICSEARCH_URL:-}" ]
  then
  echo "+ Elasticsearch" | indent
  curl -s -L "$ELASTICSEARCH_DIST_URL" > "elasticsearch.tar.gz"
  mkdir -p "$PIO_DIST_DIR/vendors/elasticsearch"
  tar -xz -f "elasticsearch.tar.gz" -C "$PIO_DIST_DIR/vendors/elasticsearch" --strip-components=1  | indent
  rm "elasticsearch.tar.gz"
  # Overrideable config file
  default_elasticsearch="$BP_DIR/config/elasticsearch.yml.erb"
  custom_elasticsearch="$BUILD_DIR/config/elasticsearch.yml.erb"
  target_elasticsearch="${PIO_DIST_DIR}/conf/elasticsearch.yml.erb"
  if [ -f "${custom_elasticsearch}" ]
    then
    echo "  Using custom 'config/elasticsearch.yml.erb'" | indent
    cp "${custom_elasticsearch}" "${target_elasticsearch}" | indent
  else
    echo "  Writing default 'elasticsearch.yml.erb'" | indent
    cp "${default_elasticsearch}" "${target_elasticsearch}" | indent
  fi
fi

if [ -d "$BP_DIR/repo" ]
  then
  echo "+ local Maven repo from buildpack (contents)" | indent
  cp -r $BP_DIR/repo $BUILD_DIR/
fi

echo "$BUILD_DIR"

topic "Configure PredictionIO"
default_pio_env="$BP_DIR/config/pio-env.sh"
custom_pio_env="$BUILD_DIR/config/pio-env.sh"
target_pio_env="${PIO_DIST_DIR}/conf/pio-env.sh"
# Overrideable config file
if [ -f "${custom_pio_env}" ]
then
  echo "Using custom 'config/pio-env.sh'" | indent
  cp "${custom_pio_env}" "${target_pio_env}" | indent
else
  echo "Writing default 'pio-env.sh'" | indent
  cp "${default_pio_env}" "${target_pio_env}" | indent
fi

default_spark="$BP_DIR/config/spark-defaults.conf.erb"
custom_spark="$BUILD_DIR/config/spark-defaults.conf.erb"
target_spark="$SPARK_HOME_DIR/conf/spark-defaults.conf.erb"
if [ -f "${custom_spark}" ]
  then
  echo "Using custom 'config/spark-defaults.conf.erb'" | indent
  cp "${custom_spark}" "${target_spark}" | indent
else
  echo "Writing default 'spark-defaults.conf.erb'" | indent
  cp "${default_spark}" "${target_spark}" | indent
fi